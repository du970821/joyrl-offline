general_cfg:
  algo_name: PPO
  device: cpu
  env_name: CartPole-v1
  eval_eps: 10
  eval_per_episode: 5
  load_checkpoint: true
  load_path: Train_CartPole-v1_PPO_20230408-113436
  max_steps: 200
  collect_eps: 10
  min_reward: 195
  mode: collect
  new_step_api: true
  render: false
  save_fig: true
  seed: 1
  show_fig: false
  test_eps: 10
  train_eps: 200
  wrapper: null
algo_cfg:

